# Lecture 3: Convolutional Neural Networks (CNN) and ResNet

## Overview 🌐

In this recap session, we consolidate the insights gained from our explorations of Stochastic Gradient Descent (SGD), Computational Graphs, Tensor Algebra, PyTorch, Convolutional Neural Networks (CNN), and ResNet. The aim is to reinforce your understanding and address any lingering questions through a comprehensive Q&A session.

## Resources 📚

- [ex1.ipynb](./ex1.ipynb) Solution to the first exercise (my live notebook)
- [ex2.ipynb](./ex2.ipynb) Solution to the second exercise
- [ex3.ipynb](./ex3.ipynb) Solution to the third exercise

## Key Topics Covered 🧠

1. **Tensor Algebra and PyTorch**:
    - A quick recap of tensor algebra operations.
    - Revisiting PyTorch, datasets, dataloaders, and torch.nn.Module.

2. **CNN and ResNet Revisited**:
    - Consolidating knowledge about Convolutional Neural Networks and their layers.
    - Summarizing the ResNet architecture and its advantages.


## Learning Objectives 🎓

- Reinforce your understanding of key concepts covered in previous lectures.
- Apply your knowledge through interactive exercises.
- Clarify doubts and deepen your insights through the Q&A session.
